
<html>
<center>
<head>
<title>
Soumyabrata Pal
</title>
<link rel="stylesheet" type="text/css" href="styles.css">
</head>
<body>


<div style="border-right: 0px solid
  black;text-align:left;padding:30px;max-width:850px">
<table>
<tr>
<td width=800>
  <h2>Soumyabrata Pal</h2>
<p>
<a href="https://research.google/locations/india/"> Google Research, India</a><br/>
email: soumyabratapal13 at gmail dot com, soumyabrata at google dot com<br/>
<A 
HREF="https://scholar.google.com/citations?user=J4UxoTEAAAAJ&hl=en">[Google scholar]</A>
<A 
HREF="https://dblp.org/pid/206/6371.html">[DBLP]</A>
<A 
HREF="https://drive.google.com/file/d/1YwZVrklp7hegdMfkBFURjfFtZHp3S9j4/view?usp=sharing">[Research Statement]</A>
  

</td>
<td>
 <img src="soumya2.jpg" width="240" height="180" style="transform:rotate(0deg);">
</td>
</tr>
</table>
<h3> About me </h3>


 <p>
 Currently, I am a Postdoctoral Researcher at Google Research, Bangalore (India). Prior to this, I completed my Ph.D in the Computer Science Department (CICS) at the University of Massachusetts Amherst advised by <a href="https://people.cs.umass.edu/~arya/">Dr. Arya Mazumdar</a>. 
During that time, I was a Visiting Graduate Student at the University of California San Diego from May - November 2021. I had also spent the summer of 2019 as a Research Intern at Ernst & Young AI Lab at Palo Alto and Spring 2020 as an Applied Scientist Intern at Amazon Search (Berkeley).   
Even earlier, I graduated from <a href="http://www.iitkgp.ac.in/">Indian Institute of Technology, Kharagpur</a> in August 2016 with a Bachelor's
degree in Electronics and Electrical Communication Engineering. 
</p>

  
<h3> Research</h3>

  <p>
    My research interests are Theoretical Machine Learning, Applied Statistics and Information Theory. More concisely, I love Statistical recovery/reconstruction problems under different structural assumptions on the data generating mechanism such as sparsity, low-rank, presence of latent clusters among others. 
    Nowadays, I am working on designing algorithms for recommender systems that can provide personalized recommendations in different settings.
    Most of my past work so far can be categorized into four topics namely 1) Latent Variable models - Mixtures of Linear Regression, Linear Classifiers and Distributions 2) Generative models for Graph Clustering - Geometric Block Model
    3) Active learning for Semi-supervised clustering - Disjoint Clusters, Overlapping Clusters and Fuzzy Clusters and 4) Statistical models for Collaborative Filtering.
 </p>

<h3> Recent News</h3>
  <p>
    New paper in ALT 2022!! Also started as a postdoc at Google Research!
  </p>
  <p>
    2 new papers in NeurIPS 2021 and 1 new paper in ITCS !!
  </p>
  <p>
    Started as a Visiting Graduate Student at UCSD from May 2021!!
  </p>  
  <p>
    New paper accepted in AISTATS 2021!!
  </p>  
  
 

<div></div>
<span></span>
  

<h3> PhD Dissertation </h3>   <p> </p>

<p> </p>
<!-- <span style="font-size:16px;font-style:italic"> Statistical learning theory</span>  -->
<p>

<ol>

<li><p><a href="https://scholarworks.umass.edu/dissertations_2/2437/"> Mixture Models in Machine Learning </a> 
</li>  
  
    
</ol>


</p>
  
  
  
<h3> Preprints </h3>   <p> </p>

<p> </p>
<!-- <span style="font-size:16px;font-style:italic"> Statistical learning theory</span>  -->
<p>

<ol>
  
  
 
  
<li><p><a href="https://arxiv.org/pdf/2210.03505.pdf"> Private and Efficient Meta-Learning with Low Rank and Sparse
Decomposition </a> <br />
with Prateek Varshney, Prateek Jain, Abhradeep Guha Thakurta, Gagan
Madan, Gaurav Aggarwal, Pradeep Shenoy, and Gaurav Srivastava <br />   
  
<li><p><a href="https://arxiv.org/abs/2210.16657"> Improved Support Recovery in One-Bit Compressed Sensing </a> <br />
with Namiko Matsumoto and Arya Mazumdar<br />
Submitted to IEEE Transactions on Information Theory. Preliminary version appeared in Innovations in Theoretical Computer Science (ITCS), 2022.<br /></p>
</li>    

<li><p><a href="http://arxiv.org/abs/2110.00744"> Random Subgraph Detection Using Queries </a> <br />
with Wasim Huleihel and Arya Mazumdar<br /> 
Submitted to JMLR.<br /></p>
  
<li><p><a href="https://arxiv.org/abs/2206.11303">Community Recovery in the Geometric Block Model</a><br />
with Sainyam Galhotra, Arya Mazumdar and Barna Saha<br />
Submitted to JMLR. Shorter versions accepted in RANDOM 2019 and AAAI 2018<br /></p>
</li>    

<li><p><a href="https://arxiv.org/abs/2202.11940">Support Recovery in Mixture Models with Sparse Parameters</a><br />
with Arya Mazumdar<br />
Submitted to JMLR. Shorter version titled "On Learning Mixture Models with Sparse Parameters " accepted at AISTATS 2022<br /></p>
</li> 
  
    
</ol>


</p>
  
  
  

<h3> Journal Publications </h3>   <p> </p>

<p> </p>
<!-- <span style="font-size:16px;font-style:italic"> Statistical learning theory</span>  -->
<p>

<ol>

<li><p><a href="https://arxiv.org/abs/1904.09618">Trace Reconstruction: Generalized and Parameterized</a> <br />
with Akshay Krishnamurthy, Arya Mazumdar and Andrew McGregor<br />
IEEE Transactions on Information Theory, 2021. Preliminary version appeared in European Symposium on Algorithms (ESA), 2019.</p>
</li>  
  
  
<li><p><a href="https://arxiv.org/abs/1904.00507"> Semisupervised Clustering by Queries and Locally Encodable Source Coding </a> <br />
with Arya Mazumdar<br />
IEEE Transactions on Information Theory, 2021. Preliminary version appeared in Advances in Neural Information Processing Systems (NeurIPS), 2017.
</li>

</ol>


</p>


<h3> Conference Publications </h3>   <p> </p>
<span style="font-size:13pt;font-style:bold"> By year </span> &nbsp;&nbsp;&nbsp;

<p> </p>
<!-- <span style="font-size:16px;font-style:italic"> Statistical learning theory</span>  -->
<p>

<ol>
  
<li><p><a href="https://arxiv.org/abs/2301.07040"> Optimal Algorithms for Latent Bandits with Cluster Structure </a> <br />
with Arun Sai Suggala, Karthikeyan Shanmugam and Prateek Jain<br /> 
International Conference on Artificial Intelligence and Statistics (AISTATS), 2023.
</li>    
  
<li><p><a href="https://arxiv.org/abs/2209.03997"> Online Low Rank Matrix Completion </a> <br />
with Prateek Jain<br /> 
International Conference on Learning Representations (ICLR), 2023.
</li>  
  
<li><p><a href="https://arxiv.org/pdf/2205.13166.pdf"> On Learning Mixture of Linear Regressions in the Non-Realizable Setting </a> <br />
with Abhishek Ghosh, Arya Mazumdar and Rajat Sen<br />
International Conference on Machine Learning (ICML), 2022.
</li>    
 
<li><p><a href="https://arxiv.org/abs/2202.11940"> On Learning Mixture Models with Sparse Parameters  </a> <br />
with Arya Mazumdar<br />
International Conference on Artificial Intelligence and Statistics (AISTATS), 2022.
</li>  
  
  
<li><p><a href="http://arxiv.org/abs/2109.01064"> Lower Bounds on the Total Variation Distance Between Mixtures of Two
 Gaussians </a> <br />
with Sami Davies, Arya Mazumdar and Cyrus Rashtchian<br />
  Algorithmic Learning Theory (ALT), 2022.</p> 
</li>  
  
<li><p><a href="https://arxiv.org/pdf/2107.09091"> Support Recovery in Universal One-bit Compressed Sensing </a> <br />
with Arya Mazumdar<br />
The 13th Innovations in Theoretical Computer Science (ITCS), 2022
</li>
  

<li><p><a href="https://arxiv.org/abs/2106.05951"> Support Recovery of Sparse Signals from a Mixture of Linear Measurements </a> <br />
with Venkata Gandikota and Arya Mazumdar<br />
Advances in Neural Information Processing Systems (NeurIPS), 2021.</p> 
</li>
  
 
<li><p><a href="https://arxiv.org/abs/2106.02212"> Fuzzy Clustering with Similarity Queries </a> <br />
with Wasim Huleihel and Arya Mazumdar<br />
Advances in Neural Information Processing Systems (NeurIPS), 2021.</p>  
</li>  
  
  
<li><p><a href="https://arxiv.org/abs/2101.12506"> Learning User Preferences in Non-Stationary Environments. </a> <br />
with Wasim Huleihel and Ofer Shayevitz<br />
International Conference on Artificial Intelligence and Statistics (AISTATS), 2021.</p>
</li>   
  
<li><p><a href="https://arxiv.org/abs/2010.12087"> Recovery of sparse linear classifiers from mixture of responses. </a> <br />
with Venkata Gandikota and Arya Mazumdar<br />
Advances in Neural Information Processing Systems (NeurIPS), 2020.</p>
</li>    
  
<li><p><a href="http://arxiv.org/abs/2006.16406"> Recovery of Sparse Signals from a Mixture of Linear Samples </a> <br />
with Arya Mazumdar<br />
International Conference on Machine Learning (ICML), 2020.</p>
</li>  
  
  
<li><p><a href="https://arxiv.org/abs/1806.11542">High Dimensional Discrete Integration by Hashing and Optimization</a> <br />
with Raj Kumar Maity and Arya Mazumdar<br />
Uncertainty in Artificial Intelligence (UAI), 2020.</p>
</li>  

<li><p><a href="https://arxiv.org/abs/2001.06776"> Algebraic and Analytic Approaches for Parameter Learning in Mixture Models  </a> <br />
with Akshay Krishnamurthy, Arya Mazumdar and Andrew McGregor<br />
 Algorithmic Learning Theory (ALT), 2020.</p> 
</li>
    
<li><p><a href="https://arxiv.org/abs/1910.12490">Same-Cluster Querying for Overlapping Clusters </a> <br />
with Wasim Huleihel, Arya Mazumdar and Muriel Medard<br />
 Advances in Neural Information Processing Systems (NeurIPS), 2019.</p>
</li>
  
<li><p><a href="https://arxiv.org/abs/1910.14106">Sample Complexity of Learning Mixture of Sparse Linear Regressions  </a> <br />
with Akshay Krishnamurthy, Arya Mazumdar and Andrew McGregor<br />
 Advances in Neural Information Processing Systems (NeurIPS), 2019.</p>
</li>
  
<li><p><a href="https://arxiv.org/abs/1904.09618">Trace Reconstruction: Generalized and Parameterized</a> <br />
with Akshay Krishnamurthy, Arya Mazumdar and Andrew McGregor<br />
European Symposium on Algorithms (ESA), 2019.</p>
</li>

  
<li><p><a href="https://arxiv.org/abs/1804.05013">Connectivity in Random Annulus Graphs and the Geometric Block Model</a><br />
with Sainyam Galhotra, Arya Mazumdar and Barna Saha<br />
International Conference on Randomization and Computation (RANDOM), 2019.<br /></p>
</li>  
    
<li><p><a href="https://arxiv.org/abs/1709.05510">The Geometric Block Model</a><br />
with Sainyam Galhotra, Arya Mazumdar and Barna Saha<br />
The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI), 2018.<br />
</li>

<li><p><a href="https://arxiv.org/abs/1904.00507">Semisupervised Clustering, AND-Queries and Locally Encodable Source Coding</a> <br />
with Arya Mazumdar<br />
Advances in Neural Information Processing Systems (NeurIPS), 2017. <b><font color="red"> Spotlight</font></b></p>
</li>

</ol>


</p>

<h3> Workshop Publications </h3>   <p> </p>
<span style="font-size:13pt;font-style:bold"> By year </span> &nbsp;&nbsp;&nbsp;

<p> </p>
<!-- <span style="font-size:16px;font-style:italic"> Statistical learning theory</span>  -->
<p>

<ol>


<li><p><a href="https://arxiv.org/abs/1709.05510">The Geometric Block Model</a> <br />
with Sainyam Galhotra, Arya Mazumdar and Barna Saha <br />
NeurIPS 2017 Workshop on Learning on Distributions, Functions, Graphs and Groups, 2017.</p>
</li>

</ol>


</p>

</body>
</center>
</html>

